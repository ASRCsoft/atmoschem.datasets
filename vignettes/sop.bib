
@article{baumer_lessons_2018,
	title = {Lessons {From} {Between} the {White} {Lines} for {Isolated} {Data} {Scientists}},
	volume = {72},
	issn = {0003-1305},
	url = {https://amstat.tandfonline.com/doi/full/10.1080/00031305.2017.1375985},
	doi = {10.1080/00031305.2017.1375985},
	abstract = {Many current and future data scientists will be “isolated”—working alone or in small teams within a larger organization. This isolation brings certain challenges as well as freedoms. Drawing on my considerable experience both working in the professional sports industry and teaching in academia, I discuss troubled waters likely to be encountered by newly minted data scientists and offer advice about how to navigate them. Neither the issues raised nor the advice given are particular to sports and should be applicable to a wide range of knowledge domains.},
	number = {1},
	urldate = {2020-01-18},
	journal = {The American Statistician},
	author = {Baumer, Benjamin S.},
	month = jan,
	year = {2018},
	pages = {66--71},
	file = {Submitted Version:/home/will/Zotero/storage/9DKJB849/Baumer - 2018 - Lessons From Between the White Lines for Isolated .pdf:application/pdf;Snapshot:/home/will/Zotero/storage/ZGMMH9QD/00031305.2017.html:text/html}
}

@article{baumer_grammar_2017,
	title = {A {Grammar} for {Reproducible} and {Painless} {Extract}-{Transform}-{Load} {Operations} on {Medium} {Data}},
	url = {https://arxiv.org/abs/1708.07073v3},
	abstract = {Many interesting data sets available on the Internet are of a medium
size---too big to fit into a personal computer's memory, but not so large that
they won't fit comfortably on its hard disk. In the coming years, data sets of
this magnitude will inform vital research in a wide array of application
domains. However, due to a variety of constraints they are cumbersome to
ingest, wrangle, analyze, and share in a reproducible fashion. These
obstructions hamper thorough peer-review and thus disrupt the forward progress
of science. We propose a predictable and pipeable framework for R (the
state-of-the-art statistical computing environment) that leverages SQL (the
venerable database architecture and query language) to make reproducible
research on medium data a painless reality.},
	language = {en},
	urldate = {2019-04-01},
	author = {Baumer, Benjamin S.},
	month = aug,
	year = {2017}
}

@misc{baumer_etl:_2017,
	title = {etl: {Extract}-{Transform}-{Load} {Framework} for {Medium} {Data}},
	copyright = {CC0},
	shorttitle = {etl},
	url = {https://CRAN.R-project.org/package=etl},
	abstract = {A predictable and pipeable framework for performing ETL (extract-transform-load) operations on publicly-accessible medium-sized data set. This package sets up the method structure and implements generic functions. Packages that depend on this package download specific data sets from the Internet, clean them up, and import them into a local or remote relational database management system.},
	urldate = {2019-04-01},
	author = {Baumer, Ben and Sievert, Carson},
	month = sep,
	year = {2017}
}

@book{hellerstein_quantitative_2008,
	title = {Quantitative {Data} {Cleaning} for {Large} {Databases}},
	abstract = {null},
	author = {Hellerstein, Joseph M.},
	year = {2008},
	file = {Citeseer - Full Text PDF:/home/will/Zotero/storage/LWBPVCGE/Hellerstein - 2008 - Quantitative Data Cleaning for Large Databases.pdf:application/pdf}
}

@misc{grange_technical_2014,
	title = {Technical note: {Averaging} wind speeds and directions},
	shorttitle = {Averaging wind speeds and directions},
	url = {https://www.researchgate.net/publication/262766424_Technical_note_Averaging_wind_speeds_and_directions},
	language = {en},
	urldate = {2019-03-25},
	author = {Grange, Stuart K.},
	month = jun,
	year = {2014},
	doi = {http://dx.doi.org/10.13140/RG.2.1.3349.2006},
	file = {(PDF) Technical note Averaging wind speeds and di.pdf:/home/will/Zotero/storage/FBQ8TGF6/(PDF) Technical note Averaging wind speeds and di.pdf:application/pdf;Snapshot:/home/will/Zotero/storage/7HPGYJFQ/262766424_Technical_note_Averaging_wind_speeds_and_directions.html:text/html}
}

@book{wmo_guide_2017,
	edition = {2014 edition updated in 2017},
	series = {{WMO}},
	title = {Guide to {Meteorological} {Instruments} and {Methods} of {Observation}},
	publisher = {WMO},
	author = {{WMO}},
	year = {2017}
}

@misc{allen_evaluation_2004,
	address = {Asheville, NC},
	title = {Evaluation of a {New} {Approach} for {Real} {Time} {Assessment} of {Wood} {Smoke} {PM}},
	url = {http://www.nescaum.org/documents/recent-nescaum-presentations-relating-to-regional-haze/evaluation-of-a-new-approach-for-real-time-assessment-of-wood-smoke-pm},
	abstract = {Wood smoke from forest fires or anthropogenic activities can be a significant contributor to
regional haze and PM2.5, but routine methods to quantify the extent of this source’s contribution
to visibility impairment and ambient levels of PM2.5 have not been developed and evaluated.
This paper evaluates an approach to semi-quantitatively measure the fraction of PM that is from
wood smoke (WS PM) in real-time. A two-wavelength AethalometerTM (Magee Scientific model
AE42) was used to measure the optical absorption of PM-1 ambient aerosol at 880 nm (BC) and
370 nm (UV-C). Certain organic aerosol components of wood smoke PM have enhanced optical
absorption at 370 relative to 880 nm (“Delta-C”). This enhanced absorption is shown to be a
specific "indicator" of WS PM, but alone is not a quantitative mass measurement. Improved
quantification of WS PM can be obtained when the two-channel Aethalometer is collocated with
continuous PM2.5 and other measurements.

A pilot study was performed to evaluate the potential for this approach in Rutland, VT between
February and July, 2004. Aethalometer measurements were made at an existing VT-DEC
monitoring site, collocated with continuous PM2.5, SO2, CO, and NOx measurements. Rutland
is a valley city surrounded by elevated terrain and subject to strong winter morning inversions,
and winter PM2.5 sample filters from this site often exhibit a distinct “wood smoke odor”. Local
mobile sources also contribute to the observed PM and BC concentrations (but not Delta-C) at
this site, primarily during weekday morning rush hour periods. Monitoring was performed
during seasons with and without wood smoke to allow assessment of mobile source signatures
without heating sources, since both have large BC components. The UNMIX model was used to
apportion measured PM2.5 into several source categories; NOx and SO2 are used to distinguish
PM contributions from WS, oil burning (primarily space heating), and mobile sources. WS PM
was associated only with the Aethalometer Delta-C measurement even in the presence of
substantial local mobile source and oil-burning aerosols.},
	author = {Allen, George A. and Babich, Peter and Poirot, Richard L.},
	month = oct,
	year = {2004},
	file = {George A. Allen et al. - 2004 - Evaluation of a New Approach for Real Time Assessm.pdf:/home/will/Zotero/storage/S7C8XRUM/George A. Allen et al. - 2004 - Evaluation of a New Approach for Real Time Assessm.pdf:application/pdf}
}

@article{zhang_joint_2017,
	title = {Joint measurements of {PM}$_{\textrm{2.5}}$ and light-absorptive {PM} in woodsmoke-dominated ambient and plume environments},
	volume = {17},
	issn = {1680-7316},
	url = {https://www.atmos-chem-phys.net/17/11441/2017/},
	doi = {https://doi.org/10.5194/acp-17-11441-2017},
	abstract = {{\textless}p{\textgreater}{\textless}strong{\textgreater}Abstract.{\textless}/strong{\textgreater} DC, also referred to as Delta-C, measures enhanced light absorption of particulate matter (PM) samples at the near-ultraviolet (UV) range relative to the near-infrared range, which has been proposed previously as a woodsmoke marker due to the presence of enhanced UV light-absorbing materials from wood combustion. In this paper, we further evaluated the applications and limitations of using DC as both a qualitative and semi-quantitative woodsmoke marker via joint continuous measurements of PM$_{\textrm{2. 5}}$ (by nephelometer pDR-1500) and light-absorptive PM (by 2-wavelength and 7-wavelength Aethalometer{\textless}span style="position:relative; bottom:0.5em; " class="text"{\textgreater}®{\textless}/span{\textgreater}) in three northeastern US cities/towns including Rutland, VT; Saranac Lake, NY and Ithaca, NY. Residential wood combustion has shown to be the predominant source of wintertime primary PM$_{\textrm{2. 5}}$ emissions in both Rutland and Saranac Lake, where we conducted ambient measurements. In Ithaca, we performed woodsmoke plume measurements. We compared the pDR-1500 against a FEM PM$_{\textrm{2. 5}}$ sampler (BAM 1020), and identified a close agreement between the two instruments in a woodsmoke-dominated ambient environment. The analysis of seasonal and diurnal trends of DC, black carbon (BC, 880{\textless}span class="thinspace"{\textgreater}{\textless}/span{\textgreater}nm) and PM$_{\textrm{2. 5}}$ concentrations supports the use of DC as an adequate qualitative marker. The strong linear relationships between PM$_{\textrm{2. 5}}$ and DC in both woodsmoke-dominated ambient and plume environments suggest that DC can reasonably serve as a semi-quantitative woodsmoke marker. We propose a DC-based indicator for woodsmoke emission, which has shown to exhibit a relatively strong linear relationship with heating demand. While we observed reproducible PM$_{\textrm{2. 5}}$–DC relationships in similar woodsmoke-dominated ambient environments, those relationships differ significantly with different environments, and among individual woodsmoke sources. Our analysis also indicates the potential for PM$_{\textrm{2. 5}}$–DC relationships to be utilized to distinguish different combustion and operating conditions of woodsmoke sources, and that DC–heating-demand relationships could be adopted to estimate woodsmoke emissions. However, future studies are needed to elucidate those relationships.{\textless}/p{\textgreater}},
	language = {English},
	number = {18},
	urldate = {2019-03-22},
	journal = {Atmospheric Chemistry and Physics},
	author = {Zhang, K. Max and Allen, George and Yang, Bo and Chen, Geng and Gu, Jiajun and Schwab, James and Felton, Dirk and Rattigan, Oliver},
	month = sep,
	year = {2017},
	pages = {11441--11452},
	file = {Snapshot:/home/will/Zotero/storage/57EQDF93/2017.html:text/html;Full Text PDF:/home/will/Zotero/storage/9ECM68NE/Zhang et al. - 2017 - Joint measurements of PMsub2. 5sub and light-.pdf:application/pdf}
}

@article{marwick_packaging_2018,
	title = {Packaging {Data} {Analytical} {Work} {Reproducibly} {Using} {R} (and {Friends})},
	volume = {72},
	issn = {0003-1305},
	url = {https://doi.org/10.1080/00031305.2017.1375986},
	doi = {10.1080/00031305.2017.1375986},
	abstract = {Computers are a central tool in the research process, enabling complex and large-scale data analysis. As computer-based research has increased in complexity, so have the challenges of ensuring that this research is reproducible. To address this challenge, we review the concept of the research compendium as a solution for providing a standard and easily recognizable way for organizing the digital materials of a research project to enable other researchers to inspect, reproduce, and extend the research. We investigate how the structure and tooling of software packages of the R programming language are being used to produce research compendia in a variety of disciplines. We also describe how software engineering tools and services are being used by researchers to streamline working with research compendia. Using real-world examples, we show how researchers can improve the reproducibility of their work using research compendia based on R packages and related tools.},
	number = {1},
	urldate = {2020-05-20},
	journal = {The American Statistician},
	author = {Marwick, Ben and Boettiger, Carl and Mullen, Lincoln},
	month = jan,
	year = {2018},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00031305.2017.1375986},
	keywords = {Computational science, Data science, Open source software, Reproducible research},
	pages = {80--88}
}

@article{bryan_excuse_2018,
	title = {Excuse {Me}, {Do} {You} {Have} a {Moment} to {Talk} {About} {Version} {Control}?},
	volume = {72},
	issn = {0003-1305},
	url = {https://doi.org/10.1080/00031305.2017.1399928},
	doi = {10.1080/00031305.2017.1399928},
	abstract = {Data analysis, statistical research, and teaching statistics have at least one thing in common: these activities all produce many files! There are data files, source code, figures, tables, prepared reports, and much more. Most of these files evolve over the course of a project and often need to be shared with others, for reading or edits, as a project unfolds. Without explicit and structured management, project organization can easily descend into chaos, taking time away from the primary work and reducing the quality of the final product. This unhappy result can be avoided by repurposing tools and workflows from the software development world, namely, distributed version control. This article describes the use of the version control system Git and the hosting site GitHub for statistical and data scientific workflows. Special attention is given to projects that use the statistical language R and, optionally, R Markdown documents. Supplementary materials include an annotated set of links to step-by-step tutorials, real world examples, and other useful learning resources. Supplementary materials for this article are available online.},
	number = {1},
	urldate = {2020-05-20},
	journal = {The American Statistician},
	author = {Bryan, Jennifer},
	month = jan,
	year = {2018},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00031305.2017.1399928},
	keywords = {Data science, Git, GitHub, R language, R Markdown, Reproducibility, Workflow},
	pages = {20--27},
	file = {Bryan - 2018 - Excuse Me, Do You Have a Moment to Talk About Vers.pdf:/home/will/Zotero/storage/57UQ4REA/Bryan - 2018 - Excuse Me, Do You Have a Moment to Talk About Vers.pdf:application/pdf}
}

@article{white_nine_2013,
	title = {Nine simple ways to make it easier to (re)use your data},
	volume = {6},
	copyright = {Copyright (c) 2015 Ethan P White, Elita Baldridge, Zachary T. Brym, Kenneth J. Locey, Daniel J. McGlinn, Sarah R. Supp},
	issn = {1918-3178},
	url = {https://ojs.library.queensu.ca/index.php/IEE/article/view/4608},
	doi = {10.4033/iee.2013.6b.6.f},
	language = {en},
	number = {2},
	urldate = {2020-05-20},
	journal = {Ideas in Ecology and Evolution},
	author = {White, Ethan P. and Baldridge, Elita and Brym, Zachary T. and Locey, Kenneth J. and McGlinn, Daniel J. and Supp, Sarah R.},
	month = aug,
	year = {2013},
	note = {Number: 2},
	keywords = {data, data reuse, data sharing, data structure},
	file = {Full Text PDF:/home/will/Zotero/storage/JD5QN8LQ/White et al. - 2013 - Nine simple ways to make it easier to (re)use your.pdf:application/pdf}
}

@article{wilkinson_fair_2016,
	title = {The {FAIR} {Guiding} {Principles} for scientific data management and stewardship},
	volume = {3},
	copyright = {2016 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/sdata201618},
	doi = {10.1038/sdata.2016.18},
	abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders—representing academia, industry, funding agencies, and scholarly publishers—have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
	language = {en},
	number = {1},
	urldate = {2020-06-16},
	journal = {Scientific Data},
	author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J. G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and ’t Hoen, Peter A. C. and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
	month = mar,
	year = {2016},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {160018},
	file = {Full Text PDF:/home/will/Zotero/storage/XT6PDBIN/Wilkinson et al. - 2016 - The FAIR Guiding Principles for scientific data ma.pdf:application/pdf}
}

@misc{db_deutz_how_2020,
	title = {How to {FAIR}: a {Danish} website to guide researchers on making research data more {FAIR}},
	url = {https://www.howtofair.dk/},
	abstract = {How To FAIR},
	language = {en-US},
	urldate = {2020-07-18},
	author = {{D.B. Deutz} and {M.C.H. Buss} and {J. S. Hansen} and {K. K. Hansen} and {K.G. Kjelmann} and {A.V. Larsen} and {E. Vlachos} and {K.F. Holmstrand}},
	year = {2020},
	doi = {10.5281/zenodo.3712065},
	howpublished = {\url{https://www.howtofair.dk/}}
}

@book{briney_data_2015,
	title = {Data {Management} for {Researchers}: {Organize}, maintain and share your data for research success},
	isbn = {978-1-78427-013-1},
	shorttitle = {Data {Management} for {Researchers}},
	abstract = {A comprehensive guide to everything scientists need to know about data management, this book is essential for researchers who need to learn how to organize, document and take care of their own data. Researchers in all disciplines are faced with the challenge of managing the growing amounts of digital data that are the foundation of their research. Kristin Briney offers practical advice and clearly explains policies and principles, in an accessible and in-depth text that will allow researchers to understand and achieve the goal of better research data management. Data Management for Researchers includes sections on: * The data problem – an introduction to the growing importance and challenges of using digital data in research. Covers both the inherent problems with managing digital information, as well as how the research landscape is changing to give more value to research datasets and code. * The data lifecycle – a framework for data’s place within the research process and how data’s role is changing. Greater emphasis on data sharing and data reuse will not only change the way we conduct research but also how we manage research data. * Planning for data management – covers the many aspects of data management and how to put them together in a data management plan. This section also includes sample data management plans. * Documenting your data – an often overlooked part of the data management process, but one that is critical to good management; data without documentation are frequently unusable. * Organizing your data – explains how to keep your data in order using organizational systems and file naming conventions. This section also covers using a database to organize and analyze content. * Improving data analysis – covers managing information through the analysis process. This section starts by comparing the management of raw and analyzed data and then describes ways to make analysis easier, such as spreadsheet best practices. It also examines practices for research code, including version control systems. * Managing secure and private data – many researchers are dealing with data that require extra security. This section outlines what data falls into this category and some of the policies that apply, before addressing the best practices for keeping data secure. * Short-term storage – deals with the practical matters of storage and backup and covers the many options available. This section also goes through the best practices to insure that data are not lost. * Preserving and archiving your data – digital data can have a long life if properly cared for. This section covers managing data in the long term including choosing good file formats and media, as well as determining who will manage the data after the end of the project. * Sharing/publishing your data – addresses how to make data sharing across research groups easier, as well as how and why to publicly share data. This section covers intellectual property and licenses for datasets, before ending with the altmetrics that measure the impact of publicly shared data. * Reusing data – as more data are shared, it becomes possible to use outside data in your research. This chapter discusses strategies for finding datasets and lays out how to cite data once you have found it. This book is designed for active scientific researchers but it is useful for anyone who wants to get more from their data: academics, educators, professionals or anyone who teaches data management, sharing and preservation. "An excellent practical treatise on the art and practice of data management, this book is essential to any researcher, regardless of subject or discipline." —Robert Buntrock, Chemical Information Bulletin},
	language = {en},
	publisher = {Pelagic Publishing Ltd},
	author = {Briney, Kristin},
	month = sep,
	year = {2015},
	note = {Google-Books-ID: gw1iCgAAQBAJ},
	keywords = {Computers / Databases / Data Warehousing, Computers / Databases / General, Computers / Web / General, Language Arts \& Disciplines / Library \& Information Science / Archives \& Special Libraries, Language Arts \& Disciplines / Library \& Information Science / General, Reference / Research, Science / Research \& Methodology}
}

@misc{christensen_narsto_2000,
	title = {{NARSTO} {Data} {Management} {Handbook}},
	url = {https://web.archive.org/web/20030401082229/http://cdiac.esd.ornl.gov:80/programs/NARSTO/pdf/dmhb_current_version.PDF},
	publisher = {NARSTO Quality Systems Science Center},
	author = {Christensen, Sigurd W. and Boden, Thomas A. and Hook, Les A. and Cheng, Meng-Dawn},
	month = feb,
	year = {2000}
}
